[data]
input_window = 24
output_window = 288

[model]
embed_dim = 64
skip_dim = 256
lape_dim = 8

geo_num_heads = 4
sem_num_heads = 2
tc_num_heads = 0
t_num_heads = 2

mlp_ratio = 4
qkv_bias = True
drop = 0
attn_drop = 0
drop_path = 0.3
s_attn_size = 3
t_attn_size = 1
enc_depth = 6

type_ln = post
type_short_path = hop
add_time_in_day = True
add_day_in_week = True

far_mask_delta=5
dtw_delta=5
time_intervals=300
cand_key_days=21
n_cluster=16
cluster_max_iter=5
cluster_method=kshape

[train]
seed = 0
seed_mode = True
xavier = False
loss_func = mask_mae


# scaler = "standard"
# load_external = True
# normal_external = False
# ext_scaler = "none"

# batch_size = 16
# seed = 0
# max_epoch = 300
# learner = "adamw"
# learning_rate = 1e-3
# weight_decay = 0.05
# lr_decay = True
# lr_scheduler = "cosinelr"
# lr_eta_min = 1e-4
# lr_decay_ratio = 0.1
# lr_warmup_epoch = 5
# lr_warmup_init = 1e-6
# clip_grad_norm = True
# max_grad_norm = 5
# use_early_stop = True
# patience = 50
# step_size = 1562
# task_level = 0
# use_curriculum_learning = True
# random_flip = True
# huber_delta = 1
# quan_delta = 0.25
# bidir = False
# far_mask_delta = 5
# dtw_delta = 5
# set_loss = "masked_mae"